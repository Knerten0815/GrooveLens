{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drummer</th>\n",
       "      <th>session</th>\n",
       "      <th>id</th>\n",
       "      <th>style</th>\n",
       "      <th>bpm</th>\n",
       "      <th>beat_type</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>midi_filename</th>\n",
       "      <th>audio_filename</th>\n",
       "      <th>duration</th>\n",
       "      <th>...</th>\n",
       "      <th>sambareggae</th>\n",
       "      <th>sangueo</th>\n",
       "      <th>secondline</th>\n",
       "      <th>shuffle</th>\n",
       "      <th>slow</th>\n",
       "      <th>soft</th>\n",
       "      <th>songo</th>\n",
       "      <th>soul</th>\n",
       "      <th>swing</th>\n",
       "      <th>venezuelan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>drummer1</td>\n",
       "      <td>drummer1/eval_session</td>\n",
       "      <td>drummer1/eval_session/1</td>\n",
       "      <td>funk/groove1</td>\n",
       "      <td>138</td>\n",
       "      <td>1</td>\n",
       "      <td>4-4</td>\n",
       "      <td>drummer1/eval_session/1_funk-groove1_138_beat_...</td>\n",
       "      <td>drummer1/eval_session/1_funk-groove1_138_beat_...</td>\n",
       "      <td>27.872308</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>drummer1</td>\n",
       "      <td>drummer1/eval_session</td>\n",
       "      <td>drummer1/eval_session/10</td>\n",
       "      <td>soul/groove10</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>4-4</td>\n",
       "      <td>drummer1/eval_session/10_soul-groove10_102_bea...</td>\n",
       "      <td>drummer1/eval_session/10_soul-groove10_102_bea...</td>\n",
       "      <td>37.691158</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>drummer1</td>\n",
       "      <td>drummer1/eval_session</td>\n",
       "      <td>drummer1/eval_session/2</td>\n",
       "      <td>funk/groove2</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>4-4</td>\n",
       "      <td>drummer1/eval_session/2_funk-groove2_105_beat_...</td>\n",
       "      <td>drummer1/eval_session/2_funk-groove2_105_beat_...</td>\n",
       "      <td>36.351218</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>drummer1</td>\n",
       "      <td>drummer1/eval_session</td>\n",
       "      <td>drummer1/eval_session/3</td>\n",
       "      <td>soul/groove3</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>4-4</td>\n",
       "      <td>drummer1/eval_session/3_soul-groove3_86_beat_4...</td>\n",
       "      <td>drummer1/eval_session/3_soul-groove3_86_beat_4...</td>\n",
       "      <td>44.716543</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>drummer1</td>\n",
       "      <td>drummer1/eval_session</td>\n",
       "      <td>drummer1/eval_session/4</td>\n",
       "      <td>soul/groove4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>4-4</td>\n",
       "      <td>drummer1/eval_session/4_soul-groove4_80_beat_4...</td>\n",
       "      <td>drummer1/eval_session/4_soul-groove4_80_beat_4...</td>\n",
       "      <td>47.987500</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    drummer                session                        id          style  \\\n",
       "0  drummer1  drummer1/eval_session   drummer1/eval_session/1   funk/groove1   \n",
       "1  drummer1  drummer1/eval_session  drummer1/eval_session/10  soul/groove10   \n",
       "2  drummer1  drummer1/eval_session   drummer1/eval_session/2   funk/groove2   \n",
       "3  drummer1  drummer1/eval_session   drummer1/eval_session/3   soul/groove3   \n",
       "4  drummer1  drummer1/eval_session   drummer1/eval_session/4   soul/groove4   \n",
       "\n",
       "   bpm  beat_type time_signature  \\\n",
       "0  138          1            4-4   \n",
       "1  102          1            4-4   \n",
       "2  105          1            4-4   \n",
       "3   86          1            4-4   \n",
       "4   80          1            4-4   \n",
       "\n",
       "                                       midi_filename  \\\n",
       "0  drummer1/eval_session/1_funk-groove1_138_beat_...   \n",
       "1  drummer1/eval_session/10_soul-groove10_102_bea...   \n",
       "2  drummer1/eval_session/2_funk-groove2_105_beat_...   \n",
       "3  drummer1/eval_session/3_soul-groove3_86_beat_4...   \n",
       "4  drummer1/eval_session/4_soul-groove4_80_beat_4...   \n",
       "\n",
       "                                      audio_filename   duration  ...  \\\n",
       "0  drummer1/eval_session/1_funk-groove1_138_beat_...  27.872308  ...   \n",
       "1  drummer1/eval_session/10_soul-groove10_102_bea...  37.691158  ...   \n",
       "2  drummer1/eval_session/2_funk-groove2_105_beat_...  36.351218  ...   \n",
       "3  drummer1/eval_session/3_soul-groove3_86_beat_4...  44.716543  ...   \n",
       "4  drummer1/eval_session/4_soul-groove4_80_beat_4...  47.987500  ...   \n",
       "\n",
       "  sambareggae  sangueo  secondline  shuffle  slow  soft  songo  soul  swing  \\\n",
       "0           0        0           0        0     0     0      0     0      0   \n",
       "1           0        0           0        0     0     0      0     1      0   \n",
       "2           0        0           0        0     0     0      0     0      0   \n",
       "3           0        0           0        0     0     0      0     1      0   \n",
       "4           0        0           0        0     0     0      0     1      0   \n",
       "\n",
       "   venezuelan  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data_processed.csv', encoding=\"latin-1\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1090 entries, 0 to 1089\n",
      "Data columns (total 100 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   drummer                  1090 non-null   object \n",
      " 1   session                  1090 non-null   object \n",
      " 2   id                       1090 non-null   object \n",
      " 3   style                    1090 non-null   object \n",
      " 4   bpm                      1090 non-null   int64  \n",
      " 5   beat_type                1090 non-null   int64  \n",
      " 6   time_signature           1090 non-null   object \n",
      " 7   midi_filename            1090 non-null   object \n",
      " 8   audio_filename           1090 non-null   object \n",
      " 9   duration                 1090 non-null   float64\n",
      " 10  split                    1090 non-null   object \n",
      " 11  onset_env_mean           1090 non-null   float64\n",
      " 12  onset_env_std            1090 non-null   float64\n",
      " 13  mfcc_mean                1090 non-null   float64\n",
      " 14  mfcc_std                 1090 non-null   float64\n",
      " 15  spectral_flux_mean       1090 non-null   float64\n",
      " 16  spectral_flux_std        1090 non-null   float64\n",
      " 17  spectral_contrast_mean   1090 non-null   float64\n",
      " 18  spectral_contrast_std    1090 non-null   float64\n",
      " 19  tonnetz_mean             1090 non-null   float64\n",
      " 20  tonnetz_std              1090 non-null   float64\n",
      " 21  rms_mean                 1090 non-null   float64\n",
      " 22  rms_std                  1090 non-null   float64\n",
      " 23  spectral_centroid_mean   1090 non-null   float64\n",
      " 24  spectral_centroid_std    1090 non-null   float64\n",
      " 25  spectral_bandwidth_mean  1090 non-null   float64\n",
      " 26  spectral_bandwidth_std   1090 non-null   float64\n",
      " 27  spectral_flatness_mean   1090 non-null   float64\n",
      " 28  spectral_flatness_std    1090 non-null   float64\n",
      " 29  tempogram_mean           1090 non-null   float64\n",
      " 30  tempogram_std            1090 non-null   float64\n",
      " 31  afrobeat                 1090 non-null   int64  \n",
      " 32  afrocuban                1090 non-null   int64  \n",
      " 33  ando                     1090 non-null   int64  \n",
      " 34  baiao                    1090 non-null   int64  \n",
      " 35  bembe                    1090 non-null   int64  \n",
      " 36  blues                    1090 non-null   int64  \n",
      " 37  bomba                    1090 non-null   int64  \n",
      " 38  bossa                    1090 non-null   int64  \n",
      " 39  brazilian                1090 non-null   int64  \n",
      " 40  breakbeat                1090 non-null   int64  \n",
      " 41  calypso                  1090 non-null   int64  \n",
      " 42  chacarera                1090 non-null   int64  \n",
      " 43  chacha                   1090 non-null   int64  \n",
      " 44  country                  1090 non-null   int64  \n",
      " 45  dance                    1090 non-null   int64  \n",
      " 46  disco                    1090 non-null   int64  \n",
      " 47  dominican                1090 non-null   int64  \n",
      " 48  fast                     1090 non-null   int64  \n",
      " 49  folk                     1090 non-null   int64  \n",
      " 50  frevo                    1090 non-null   int64  \n",
      " 51  funk                     1090 non-null   int64  \n",
      " 52  fusion                   1090 non-null   int64  \n",
      " 53  gospel                   1090 non-null   int64  \n",
      " 54  groove1                  1090 non-null   int64  \n",
      " 55  groove10                 1090 non-null   int64  \n",
      " 56  groove2                  1090 non-null   int64  \n",
      " 57  groove3                  1090 non-null   int64  \n",
      " 58  groove4                  1090 non-null   int64  \n",
      " 59  groove5                  1090 non-null   int64  \n",
      " 60  groove6                  1090 non-null   int64  \n",
      " 61  groove7                  1090 non-null   int64  \n",
      " 62  groove8                  1090 non-null   int64  \n",
      " 63  groove9                  1090 non-null   int64  \n",
      " 64  halftime                 1090 non-null   int64  \n",
      " 65  hiphop                   1090 non-null   int64  \n",
      " 66  ijexa                    1090 non-null   int64  \n",
      " 67  indie                    1090 non-null   int64  \n",
      " 68  jazz                     1090 non-null   int64  \n",
      " 69  joropo                   1090 non-null   int64  \n",
      " 70  klezmer                  1090 non-null   int64  \n",
      " 71  latin                    1090 non-null   int64  \n",
      " 72  linear                   1090 non-null   int64  \n",
      " 73  maracatu                 1090 non-null   int64  \n",
      " 74  march                    1090 non-null   int64  \n",
      " 75  mediumfast               1090 non-null   int64  \n",
      " 76  merengue                 1090 non-null   int64  \n",
      " 77  middleeastern            1090 non-null   int64  \n",
      " 78  motown                   1090 non-null   int64  \n",
      " 79  neworleans               1090 non-null   int64  \n",
      " 80  pop                      1090 non-null   int64  \n",
      " 81  prog                     1090 non-null   int64  \n",
      " 82  punk                     1090 non-null   int64  \n",
      " 83  purdieshuffle            1090 non-null   int64  \n",
      " 84  reggae                   1090 non-null   int64  \n",
      " 85  reggaeton                1090 non-null   int64  \n",
      " 86  rhumba                   1090 non-null   int64  \n",
      " 87  rock                     1090 non-null   int64  \n",
      " 88  rockabilly               1090 non-null   int64  \n",
      " 89  samba                    1090 non-null   int64  \n",
      " 90  sambareggae              1090 non-null   int64  \n",
      " 91  sangueo                  1090 non-null   int64  \n",
      " 92  secondline               1090 non-null   int64  \n",
      " 93  shuffle                  1090 non-null   int64  \n",
      " 94  slow                     1090 non-null   int64  \n",
      " 95  soft                     1090 non-null   int64  \n",
      " 96  songo                    1090 non-null   int64  \n",
      " 97  soul                     1090 non-null   int64  \n",
      " 98  swing                    1090 non-null   int64  \n",
      " 99  venezuelan               1090 non-null   int64  \n",
      "dtypes: float64(21), int64(71), object(8)\n",
      "memory usage: 851.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the column spectrum_filename to the dataframe data. But not at the end, instead it should follow the column audio_filename\n",
    "data.insert(data.columns.get_loc('audio_filename') + 1, 'spectrum_filename', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['spectrum_filename'] = data.audio_filename.str.replace('.wav', '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'drummer1/eval_session/1_funk-groove1_138_beat_4-4.png'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['spectrum_filename'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data\n",
    "data_train, data_test, = train_test_split(data, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split again into validation and test (Split is now 70/15/15)\n",
    "data_test, data_validation = train_test_split(data_train, test_size=0.5, random_state=42,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(763, 101) (381, 101) (382, 101)\n",
      "Train data share:  0.7\n",
      "Validation data share:  0.3504587155963303\n",
      "Test data share:  0.3495412844036697\n"
     ]
    }
   ],
   "source": [
    "# check the distribution after the split\n",
    "print(data_train.shape, data_test.shape, data_validation.shape, )\n",
    "print(\"Train data share: \", data_train.shape[0] / data.shape[0])\n",
    "print(\"Validation data share: \", data_validation.shape[0]/ data.shape[0])\n",
    "print(\"Test data share: \", data_test.shape[0] / data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Generators are the dataloaders for the CNN. They just define how the images are \"fed\" to the cnn, like where is the path to the images, what are the labels to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['afrobeat', 'afrocuban', 'ando', 'baiao', 'bembe', 'blues', 'bomba',\n",
       "       'bossa', 'brazilian', 'breakbeat', 'calypso', 'chacarera', 'chacha',\n",
       "       'country', 'dance', 'disco', 'dominican', 'fast', 'folk', 'frevo',\n",
       "       'funk', 'fusion', 'gospel', 'groove1', 'groove10', 'groove2', 'groove3',\n",
       "       'groove4', 'groove5', 'groove6', 'groove7', 'groove8', 'groove9',\n",
       "       'halftime', 'hiphop', 'ijexa', 'indie', 'jazz', 'joropo', 'klezmer',\n",
       "       'latin', 'linear', 'maracatu', 'march', 'mediumfast', 'merengue',\n",
       "       'middleeastern', 'motown', 'neworleans', 'pop', 'prog', 'punk',\n",
       "       'purdieshuffle', 'reggae', 'reggaeton', 'rhumba', 'rock', 'rockabilly',\n",
       "       'samba', 'sambareggae', 'sangueo', 'secondline', 'shuffle', 'slow',\n",
       "       'soft', 'songo', 'soul', 'swing', 'venezuelan'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_columns = data.columns[32:]\n",
    "label_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69,)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_columns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 162 validated image filenames.\n",
      "Found 88 validated image filenames.\n",
      "Found 74 validated image filenames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kevin\\miniconda3\\envs\\audio_data_science_gpu\\lib\\site-packages\\keras\\preprocessing\\image.py:1139: UserWarning: Found 601 invalid image filename(s) in x_col=\"spectrum_filename\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kevin\\miniconda3\\envs\\audio_data_science_gpu\\lib\\site-packages\\keras\\preprocessing\\image.py:1139: UserWarning: Found 294 invalid image filename(s) in x_col=\"spectrum_filename\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kevin\\miniconda3\\envs\\audio_data_science_gpu\\lib\\site-packages\\keras\\preprocessing\\image.py:1139: UserWarning: Found 307 invalid image filename(s) in x_col=\"spectrum_filename\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "path_images = os.path.join('Datasets', 'spectrums')\n",
    "\n",
    "# Normalize images\n",
    "image_generator = ImageDataGenerator(\n",
    "    rescale=1.0/255\n",
    ")\n",
    "\n",
    "# Define the data generators\n",
    "train_generator = image_generator.flow_from_dataframe(\n",
    "    dataframe=data_train,\n",
    "    directory=path_images,\n",
    "    x_col=\"spectrum_filename\",\n",
    "    y_col=label_columns,\n",
    "    target_size=(250, 100),\n",
    "    batch_size=32,\n",
    "    class_mode=\"raw\",\n",
    "    color_mode=\"rgb\" # add color mode\n",
    ")\n",
    "\n",
    "val_generator = image_generator.flow_from_dataframe(\n",
    "    dataframe=data_validation,\n",
    "    directory=path_images,\n",
    "    x_col=\"spectrum_filename\",\n",
    "    y_col=label_columns,\n",
    "    target_size=(250, 100),\n",
    "    batch_size=32,\n",
    "    class_mode=\"raw\",\n",
    "    color_mode=\"rgb\", #add color mode,\n",
    "    shuffle=False,  # this is crucial for later evaluation!\n",
    ")\n",
    "\n",
    "test_generator = image_generator.flow_from_dataframe(\n",
    "    dataframe=data_test,\n",
    "    directory=path_images,\n",
    "    x_col=\"spectrum_filename\",\n",
    "    y_col=label_columns,\n",
    "    target_size=(250, 100),\n",
    "    batch_size=32,\n",
    "    class_mode=\"raw\",\n",
    "    color_mode=\"rgb\", #add color mode,\n",
    "    shuffle=False,  # this is crucial for later evaluation!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 250, 100, 3)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_generator)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 250, 100, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 248, 98, 32)       896       \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPoolin  (None, 124, 49, 32)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 122, 47, 64)       18496     \n",
      "                                                                 \n",
      " max_pooling2d_26 (MaxPoolin  (None, 61, 23, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 59, 21, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_27 (MaxPoolin  (None, 29, 10, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 27, 8, 128)        147584    \n",
      "                                                                 \n",
      " max_pooling2d_28 (MaxPoolin  (None, 13, 4, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 11, 2, 128)        147584    \n",
      "                                                                 \n",
      " max_pooling2d_29 (MaxPoolin  (None, 5, 1, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 640)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               82048     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 69)                8901      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 479,365\n",
      "Trainable params: 479,365\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define the input shape\n",
    "inputs = Input(shape=(250, 100, 3))\n",
    "\n",
    "# Define the CNN architecture\n",
    "x = Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "outputs = Dense(69, activation=\"sigmoid\")(x)\n",
    "\n",
    "# Create the model\n",
    "cnn_model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def compileCNN(cnn):\n",
    "    metrics = [\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    "\n",
    "    # Compile the model\n",
    "    cnn.compile(optimizer='adam',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=\"accuracy\") #metrics)\n",
    "    \n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCallbacks(path):\n",
    "    # Create a callback that saves the model's weights\n",
    "    checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(filepath=path,\n",
    "                                                    save_weights_only=True,    # saving only the weights, because we have the architecture of the model\n",
    "                                                    verbose=1, \n",
    "                                                    monitor='val_accuracy',    # we are monitoring the accuracy on the validation set\n",
    "                                                    mode='max',                # the greatest accuracy on the validation is the best outcome\n",
    "                                                    save_best_only=True)       # we only want to save the best model. The other chechpoints are not interesting to us\n",
    "    \n",
    "    early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)\n",
    "\n",
    "    return checkpoint_cb, early_stopping_cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainCNN(cnn, train_generator, validation_generator, checkpoint_callback, early_stopping_callback):\n",
    "    history = cnn.fit(\n",
    "        train_generator,\n",
    "        epochs=100,\n",
    "        validation_data=validation_generator,\n",
    "        verbose=1,\n",
    "        callbacks=[checkpoint_callback, early_stopping_callback],  # Pass callback to training\n",
    "    )\n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.5893 - accuracy: 0.0000e+00\n",
      "Epoch 1: val_accuracy improved from -inf to 0.00000, saving model to data\\models\\first_cnn.ckpt\n",
      "6/6 [==============================] - 7s 899ms/step - loss: 0.5893 - accuracy: 0.0000e+00 - val_loss: 0.4223 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2824 - accuracy: 0.0000e+00\n",
      "Epoch 2: val_accuracy improved from 0.00000 to 0.06818, saving model to data\\models\\first_cnn.ckpt\n",
      "6/6 [==============================] - 3s 590ms/step - loss: 0.2824 - accuracy: 0.0000e+00 - val_loss: 0.1516 - val_accuracy: 0.0682\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1187 - accuracy: 0.1481\n",
      "Epoch 3: val_accuracy improved from 0.06818 to 0.13636, saving model to data\\models\\first_cnn.ckpt\n",
      "6/6 [==============================] - 4s 617ms/step - loss: 0.1187 - accuracy: 0.1481 - val_loss: 0.1001 - val_accuracy: 0.1364\n",
      "Epoch 4/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.0890 - accuracy: 0.2937\n",
      "Epoch 4: val_accuracy improved from 0.13636 to 0.36364, saving model to data\\models\\first_cnn.ckpt\n",
      "6/6 [==============================] - 3s 599ms/step - loss: 0.0890 - accuracy: 0.2963 - val_loss: 0.0923 - val_accuracy: 0.3636\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0855 - accuracy: 0.3025\n",
      "Epoch 5: val_accuracy did not improve from 0.36364\n",
      "6/6 [==============================] - 3s 613ms/step - loss: 0.0855 - accuracy: 0.3025 - val_loss: 0.0903 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0824 - accuracy: 0.2222\n",
      "Epoch 6: val_accuracy did not improve from 0.36364\n",
      "6/6 [==============================] - 3s 510ms/step - loss: 0.0824 - accuracy: 0.2222 - val_loss: 0.0842 - val_accuracy: 0.3636\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0789 - accuracy: 0.3642\n",
      "Epoch 7: val_accuracy did not improve from 0.36364\n",
      "6/6 [==============================] - 3s 520ms/step - loss: 0.0789 - accuracy: 0.3642 - val_loss: 0.0830 - val_accuracy: 0.3636\n"
     ]
    }
   ],
   "source": [
    "cnn_path = os.path.join('data', 'models', 'first_cnn.ckpt')\n",
    "\n",
    "try:\n",
    "    cnn_model.load_weights(cnn_path)\n",
    "except:\n",
    "    cnn_model = compileCNN(cnn_model)\n",
    "    checkpoint_callback, early_stopping_callback = createCallbacks(cnn_path)\n",
    "    cnn_model = trainCNN(cnn_model, train_generator, val_generator, checkpoint_callback, early_stopping_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 225ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = cnn_model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_df = pd.DataFrame(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_df[y_pred_df > 0.1] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [381, 74]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[128], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multilabel_confusion_matrix\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mevaluation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m evaluate_model, plot_confusion_matrix\n\u001b[1;32m----> 4\u001b[0m multi_conf_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mmultilabel_confusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabel_columns\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m plot_confusion_matrix(multi_conf_matrix, \u001b[38;5;28mlist\u001b[39m(label_columns), label_columns[:\u001b[38;5;241m10\u001b[39m])\n\u001b[0;32m      6\u001b[0m plot_confusion_matrix(multi_conf_matrix, \u001b[38;5;28mlist\u001b[39m(label_columns), label_columns[\u001b[38;5;241m10\u001b[39m:\u001b[38;5;241m20\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\audio_data_science_gpu\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\audio_data_science_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:508\u001b[0m, in \u001b[0;36mmultilabel_confusion_matrix\u001b[1;34m(y_true, y_pred, sample_weight, labels, samplewise)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m    399\u001b[0m     {\n\u001b[0;32m    400\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    409\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, samplewise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    410\u001b[0m ):\n\u001b[0;32m    411\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute a confusion matrix for each class or sample.\u001b[39;00m\n\u001b[0;32m    412\u001b[0m \n\u001b[0;32m    413\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 0.21\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;124;03m            [1, 2]]])\u001b[39;00m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 508\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    510\u001b[0m         sample_weight \u001b[38;5;241m=\u001b[39m column_or_1d(sample_weight)\n",
      "File \u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\audio_data_science_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:85\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \n\u001b[0;32m     61\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     87\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\audio_data_science_gpu\\lib\\site-packages\\sklearn\\utils\\validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    460\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [381, 74]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from evaluation import evaluate_model, plot_confusion_matrix\n",
    "\n",
    "multi_conf_matrix = multilabel_confusion_matrix(data_test[label_columns], y_pred_df)\n",
    "plot_confusion_matrix(multi_conf_matrix, list(label_columns), label_columns[:10])\n",
    "plot_confusion_matrix(multi_conf_matrix, list(label_columns), label_columns[10:20])\n",
    "plot_confusion_matrix(multi_conf_matrix, list(label_columns), label_columns[20:30])\n",
    "plot_confusion_matrix(multi_conf_matrix, list(label_columns), label_columns[30:40])\n",
    "plot_confusion_matrix(multi_conf_matrix, list(label_columns), label_columns[40:50])\n",
    "plot_confusion_matrix(multi_conf_matrix, list(label_columns), label_columns[50:60])\n",
    "plot_confusion_matrix(multi_conf_matrix, list(label_columns), label_columns[60:69])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
