{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPECTRUM_FOLDERNAME = 'spectrums_cropped_small' # the folder containing the spectrums to load\n",
    "IMG_HEIGHT = 200\n",
    "IMG_WIDTH = 500\n",
    "FILE_SUFFIX = \"UPDATED_ARCHITECTURE\"\n",
    "EPOCHS = 100\n",
    "EARLY_STOPPING_PATIENCE = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drummer</th>\n",
       "      <th>session</th>\n",
       "      <th>id</th>\n",
       "      <th>style</th>\n",
       "      <th>simplified_style</th>\n",
       "      <th>bpm</th>\n",
       "      <th>beat_type</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>midi_filename</th>\n",
       "      <th>audio_filename</th>\n",
       "      <th>...</th>\n",
       "      <th>rms_std</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>spectral_centroid_std</th>\n",
       "      <th>spectral_bandwidth_mean</th>\n",
       "      <th>spectral_bandwidth_std</th>\n",
       "      <th>spectral_flatness_mean</th>\n",
       "      <th>spectral_flatness_std</th>\n",
       "      <th>tempogram_mean</th>\n",
       "      <th>tempogram_std</th>\n",
       "      <th>spectrum_filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>drummer1</td>\n",
       "      <td>drummer1/eval_session</td>\n",
       "      <td>drummer1/eval_session/1</td>\n",
       "      <td>funk/groove1</td>\n",
       "      <td>funk</td>\n",
       "      <td>138</td>\n",
       "      <td>1</td>\n",
       "      <td>4-4</td>\n",
       "      <td>drummer1/eval_session/1_funk-groove1_138_beat_...</td>\n",
       "      <td>drummer1/eval_session/1_funk-groove1_138_beat_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056157</td>\n",
       "      <td>5608.665252</td>\n",
       "      <td>2501.480437</td>\n",
       "      <td>4647.658427</td>\n",
       "      <td>941.263597</td>\n",
       "      <td>0.090434</td>\n",
       "      <td>0.124045</td>\n",
       "      <td>0.294583</td>\n",
       "      <td>0.171183</td>\n",
       "      <td>drummer1/eval_session/1_funk-groove1_138_beat_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>drummer1</td>\n",
       "      <td>drummer1/eval_session</td>\n",
       "      <td>drummer1/eval_session/10</td>\n",
       "      <td>soul/groove10</td>\n",
       "      <td>funk</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>4-4</td>\n",
       "      <td>drummer1/eval_session/10_soul-groove10_102_bea...</td>\n",
       "      <td>drummer1/eval_session/10_soul-groove10_102_bea...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062846</td>\n",
       "      <td>7204.425221</td>\n",
       "      <td>3338.747216</td>\n",
       "      <td>5212.773742</td>\n",
       "      <td>1194.914650</td>\n",
       "      <td>0.148189</td>\n",
       "      <td>0.143111</td>\n",
       "      <td>0.267859</td>\n",
       "      <td>0.234713</td>\n",
       "      <td>drummer1/eval_session/10_soul-groove10_102_bea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>drummer1</td>\n",
       "      <td>drummer1/eval_session</td>\n",
       "      <td>drummer1/eval_session/2</td>\n",
       "      <td>funk/groove2</td>\n",
       "      <td>funk</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>4-4</td>\n",
       "      <td>drummer1/eval_session/2_funk-groove2_105_beat_...</td>\n",
       "      <td>drummer1/eval_session/2_funk-groove2_105_beat_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061557</td>\n",
       "      <td>6172.809370</td>\n",
       "      <td>3874.975566</td>\n",
       "      <td>4711.894615</td>\n",
       "      <td>1483.392124</td>\n",
       "      <td>0.116454</td>\n",
       "      <td>0.132516</td>\n",
       "      <td>0.238676</td>\n",
       "      <td>0.153792</td>\n",
       "      <td>drummer1/eval_session/2_funk-groove2_105_beat_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>drummer1</td>\n",
       "      <td>drummer1/eval_session</td>\n",
       "      <td>drummer1/eval_session/3</td>\n",
       "      <td>soul/groove3</td>\n",
       "      <td>funk</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>4-4</td>\n",
       "      <td>drummer1/eval_session/3_soul-groove3_86_beat_4...</td>\n",
       "      <td>drummer1/eval_session/3_soul-groove3_86_beat_4...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053402</td>\n",
       "      <td>5704.099294</td>\n",
       "      <td>3309.100713</td>\n",
       "      <td>5098.568553</td>\n",
       "      <td>1251.293005</td>\n",
       "      <td>0.101191</td>\n",
       "      <td>0.128717</td>\n",
       "      <td>0.149444</td>\n",
       "      <td>0.144291</td>\n",
       "      <td>drummer1/eval_session/3_soul-groove3_86_beat_4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>drummer1</td>\n",
       "      <td>drummer1/eval_session</td>\n",
       "      <td>drummer1/eval_session/4</td>\n",
       "      <td>soul/groove4</td>\n",
       "      <td>funk</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>4-4</td>\n",
       "      <td>drummer1/eval_session/4_soul-groove4_80_beat_4...</td>\n",
       "      <td>drummer1/eval_session/4_soul-groove4_80_beat_4...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046688</td>\n",
       "      <td>8042.372855</td>\n",
       "      <td>3504.921958</td>\n",
       "      <td>5396.953176</td>\n",
       "      <td>999.442925</td>\n",
       "      <td>0.181278</td>\n",
       "      <td>0.149775</td>\n",
       "      <td>0.115379</td>\n",
       "      <td>0.128980</td>\n",
       "      <td>drummer1/eval_session/4_soul-groove4_80_beat_4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    drummer                session                        id          style  \\\n",
       "0  drummer1  drummer1/eval_session   drummer1/eval_session/1   funk/groove1   \n",
       "1  drummer1  drummer1/eval_session  drummer1/eval_session/10  soul/groove10   \n",
       "2  drummer1  drummer1/eval_session   drummer1/eval_session/2   funk/groove2   \n",
       "3  drummer1  drummer1/eval_session   drummer1/eval_session/3   soul/groove3   \n",
       "4  drummer1  drummer1/eval_session   drummer1/eval_session/4   soul/groove4   \n",
       "\n",
       "  simplified_style  bpm  beat_type time_signature  \\\n",
       "0             funk  138          1            4-4   \n",
       "1             funk  102          1            4-4   \n",
       "2             funk  105          1            4-4   \n",
       "3             funk   86          1            4-4   \n",
       "4             funk   80          1            4-4   \n",
       "\n",
       "                                       midi_filename  \\\n",
       "0  drummer1/eval_session/1_funk-groove1_138_beat_...   \n",
       "1  drummer1/eval_session/10_soul-groove10_102_bea...   \n",
       "2  drummer1/eval_session/2_funk-groove2_105_beat_...   \n",
       "3  drummer1/eval_session/3_soul-groove3_86_beat_4...   \n",
       "4  drummer1/eval_session/4_soul-groove4_80_beat_4...   \n",
       "\n",
       "                                      audio_filename  ...   rms_std  \\\n",
       "0  drummer1/eval_session/1_funk-groove1_138_beat_...  ...  0.056157   \n",
       "1  drummer1/eval_session/10_soul-groove10_102_bea...  ...  0.062846   \n",
       "2  drummer1/eval_session/2_funk-groove2_105_beat_...  ...  0.061557   \n",
       "3  drummer1/eval_session/3_soul-groove3_86_beat_4...  ...  0.053402   \n",
       "4  drummer1/eval_session/4_soul-groove4_80_beat_4...  ...  0.046688   \n",
       "\n",
       "  spectral_centroid_mean  spectral_centroid_std  spectral_bandwidth_mean  \\\n",
       "0            5608.665252            2501.480437              4647.658427   \n",
       "1            7204.425221            3338.747216              5212.773742   \n",
       "2            6172.809370            3874.975566              4711.894615   \n",
       "3            5704.099294            3309.100713              5098.568553   \n",
       "4            8042.372855            3504.921958              5396.953176   \n",
       "\n",
       "   spectral_bandwidth_std  spectral_flatness_mean  spectral_flatness_std  \\\n",
       "0              941.263597                0.090434               0.124045   \n",
       "1             1194.914650                0.148189               0.143111   \n",
       "2             1483.392124                0.116454               0.132516   \n",
       "3             1251.293005                0.101191               0.128717   \n",
       "4              999.442925                0.181278               0.149775   \n",
       "\n",
       "   tempogram_mean  tempogram_std  \\\n",
       "0        0.294583       0.171183   \n",
       "1        0.267859       0.234713   \n",
       "2        0.238676       0.153792   \n",
       "3        0.149444       0.144291   \n",
       "4        0.115379       0.128980   \n",
       "\n",
       "                                   spectrum_filename  \n",
       "0  drummer1/eval_session/1_funk-groove1_138_beat_...  \n",
       "1  drummer1/eval_session/10_soul-groove10_102_bea...  \n",
       "2  drummer1/eval_session/2_funk-groove2_105_beat_...  \n",
       "3  drummer1/eval_session/3_soul-groove3_86_beat_4...  \n",
       "4  drummer1/eval_session/4_soul-groove4_80_beat_4...  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data_balanced_processed_new.csv', encoding=\"latin-1\")\n",
    "#data.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1200 entries, 0 to 1199\n",
      "Data columns (total 38 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   drummer                  1200 non-null   object \n",
      " 1   session                  1200 non-null   object \n",
      " 2   id                       1200 non-null   object \n",
      " 3   style                    1200 non-null   object \n",
      " 4   simplified_style         1200 non-null   object \n",
      " 5   bpm                      1200 non-null   int64  \n",
      " 6   beat_type                1200 non-null   int64  \n",
      " 7   time_signature           1200 non-null   object \n",
      " 8   midi_filename            1200 non-null   object \n",
      " 9   audio_filename           1200 non-null   object \n",
      " 10  duration                 1200 non-null   float64\n",
      " 11  split                    1200 non-null   object \n",
      " 12  start                    1200 non-null   float64\n",
      " 13  end                      1200 non-null   float64\n",
      " 14  times_sampled            1200 non-null   int64  \n",
      " 15  possible_samples         1200 non-null   float64\n",
      " 16  oversampling_ratio       1200 non-null   float64\n",
      " 17  onset_env_mean           1200 non-null   float64\n",
      " 18  onset_env_std            1200 non-null   float64\n",
      " 19  mfcc_mean                1200 non-null   float64\n",
      " 20  mfcc_std                 1200 non-null   float64\n",
      " 21  spectral_flux_mean       1200 non-null   float64\n",
      " 22  spectral_flux_std        1200 non-null   float64\n",
      " 23  spectral_contrast_mean   1200 non-null   float64\n",
      " 24  spectral_contrast_std    1200 non-null   float64\n",
      " 25  tonnetz_mean             1200 non-null   float64\n",
      " 26  tonnetz_std              1200 non-null   float64\n",
      " 27  rms_mean                 1200 non-null   float64\n",
      " 28  rms_std                  1200 non-null   float64\n",
      " 29  spectral_centroid_mean   1200 non-null   float64\n",
      " 30  spectral_centroid_std    1200 non-null   float64\n",
      " 31  spectral_bandwidth_mean  1200 non-null   float64\n",
      " 32  spectral_bandwidth_std   1200 non-null   float64\n",
      " 33  spectral_flatness_mean   1200 non-null   float64\n",
      " 34  spectral_flatness_std    1200 non-null   float64\n",
      " 35  tempogram_mean           1200 non-null   float64\n",
      " 36  tempogram_std            1200 non-null   float64\n",
      " 37  spectrum_filename        1200 non-null   object \n",
      "dtypes: float64(25), int64(3), object(10)\n",
      "memory usage: 356.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "encoded_style\n",
       "0    200\n",
       "1    200\n",
       "4    200\n",
       "5    200\n",
       "3    200\n",
       "2    200\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the target variable\n",
    "data[\"encoded_style\"] = label_encoder.fit_transform(data.simplified_style)\n",
    "data.encoded_style.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we sampled some audio files multiple times. We should prevent data leakage between train and test/validation sets. We do this by using the group shuffle split from scikit-learn. This messes up the distribution of genres a bit though. To find the best split, that has no data leakage and a good distribution of genres, we will use the forbidden technique of random state hacking! We are using it to create a good split and not to overfit the model, so it is fine i think.\n",
    "We just check the genre distributions produced by different random states and choose the one, that differs the least from a perfectly balanced distributon."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "# random state hacking\n",
    "rnd_states = []\n",
    "for i in range(9999):\n",
    "    groups = data['audio_filename']\n",
    "    gss = GroupShuffleSplit(n_splits=5, train_size=0.7, random_state=i)\n",
    "    for train_indices, remaining_indices in gss.split(X=data, groups=groups):\n",
    "        #GroupShuffleSplit.split() returns an iterator and is meant to be used in a loop. So I guess I need to fill this loop with code...\n",
    "        useless_variable = None\n",
    "        \n",
    "    train_df = data.iloc[train_indices].sample(frac=1.0, random_state=42)\n",
    "    remaining_df = data.iloc[remaining_indices]\n",
    "\n",
    "    # calcuate how balanced the data sets are\n",
    "    balanced_ratio = 1/6\n",
    "    train_ratios = train_df.simplified_style.value_counts(normalize=True).values\n",
    "    remaining_ratios = remaining_df.simplified_style.value_counts(normalize=True).values\n",
    "    train_offset = (abs(train_ratios - balanced_ratio)).sum()\n",
    "    remaining_offset = (abs(remaining_ratios - balanced_ratio)).sum()\n",
    "    balanced_offset = train_offset + remaining_offset # the lower the better\n",
    "    \n",
    "    # save random state i and blanced_offset in a dictionary\n",
    "    rnd_states.append({'rnd_state': i, 'balanced_offset': balanced_offset})\n",
    "\n",
    "# print the random state with the lowest balanced offset\n",
    "print(min(rnd_states, key=lambda x:x['balanced_offset']))\n",
    "\n",
    "group_shuffle_rnd_state = min(rnd_states, key=lambda x:x['balanced_offset']).get('rnd_state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "group_shuffle_rnd_state = 8698"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data leakage = False\n",
      "\n",
      "Train data genre distribution\n",
      "simplified_style\n",
      "latin     0.169082\n",
      "rock      0.167874\n",
      "funk      0.167874\n",
      "hiphop    0.166667\n",
      "jazz      0.166667\n",
      "pop       0.161836\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Remaining data genre distribution\n",
      "simplified_style\n",
      "pop       0.177419\n",
      "jazz      0.166667\n",
      "hiphop    0.166667\n",
      "funk      0.163978\n",
      "rock      0.163978\n",
      "latin     0.161290\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# prevent data leakage by grouping splits by audio_filename\n",
    "groups = data['audio_filename']\n",
    "gss = GroupShuffleSplit(n_splits=5, train_size=0.7, random_state=group_shuffle_rnd_state)\n",
    "for train_indices, remaining_indices in gss.split(X=data, groups=groups):\n",
    "    #GroupShuffleSplit.split() returns a tuple instead of Numpy.nparray when used outside of a for loop somehow. So I guess I need to fill this loop with code...\n",
    "    useless_variable = None\n",
    "\n",
    "\n",
    "# create dataframe from group split indices and shuffle the train dataframe\n",
    "data_train = data.iloc[train_indices].sample(frac=1.0, random_state=42)\n",
    "remaining_data = data.iloc[remaining_indices]\n",
    "\n",
    "# check for data leakage\n",
    "print('Data leakage =', data_train['audio_filename'].isin(remaining_data['audio_filename']).any())\n",
    "\n",
    "# check genre distribution\n",
    "print(\"\\nTrain data genre distribution\")\n",
    "print(data_train.simplified_style.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nRemaining data genre distribution\")\n",
    "print(remaining_data.simplified_style.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(828, 39) (186, 39) (186, 39)\n",
      "Train data share:  0.69\n",
      "Validation data share:  0.155\n",
      "Test data share:  0.155\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # split the remaining data into test and validation data sets. No need to worry about data leakage, because these datasets are not used for training.\n",
    "data_test, data_validation = train_test_split(remaining_data, test_size=0.5, random_state=42,)\n",
    "data_test.shape\n",
    "\n",
    "# check the distribution after the split\n",
    "print(data_train.shape, data_test.shape, data_validation.shape, )\n",
    "print(\"Train data share: \", data_train.shape[0] / data.shape[0])\n",
    "print(\"Validation data share: \", data_validation.shape[0]/ data.shape[0])\n",
    "print(\"Test data share: \", data_test.shape[0] / data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "audio_filename\n",
       "drummer1/session1/101_dance-disco_120_beat_4-4.wav      24\n",
       "drummer7/session2/80_country_78_beat_4-4.wav            24\n",
       "drummer1/session3/6_dance-disco_120_beat_4-4.wav        23\n",
       "drummer8/session1/4_hiphop_90_beat_4-4.wav              10\n",
       "drummer8/session1/5_hiphop_90_beat_4-4.wav              10\n",
       "                                                        ..\n",
       "drummer7/eval_session/8_rock-groove8_65_beat_4-4.wav     1\n",
       "drummer9/session1/19_rock_120_beat_4-4.wav               1\n",
       "drummer7/session3/109_rock_95_beat_4-4.wav               1\n",
       "drummer3/session1/44_rock_120_beat_4-4.wav               1\n",
       "drummer3/session2/30_rock_92_beat_4-4.wav                1\n",
       "Name: count, Length: 298, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.audio_filename.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "audio_filename\n",
       "drummer7/session3/11_pop-soft_83_beat_4-4.wav            15\n",
       "drummer1/session2/10_country_114_beat_4-4.wav             9\n",
       "drummer7/session1/17_hiphop_100_beat_4-4.wav              6\n",
       "drummer7/session2/96_pop_142_beat_4-4.wav                 5\n",
       "drummer7/session3/106_hiphop_70_beat_4-4.wav              5\n",
       "                                                         ..\n",
       "drummer6/session3/1_rock_90_beat_4-4.wav                  1\n",
       "drummer6/session1/5_rock_60_beat_6-8.wav                  1\n",
       "drummer3/session2/9_rock_100_beat_4-4.wav                 1\n",
       "drummer7/eval_session/2_funk-groove2_105_beat_4-4.wav     1\n",
       "drummer3/session1/48_rock_120_beat_4-4.wav                1\n",
       "Name: count, Length: 87, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_validation.audio_filename.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "audio_filename\n",
       "drummer1/session2/10_country_114_beat_4-4.wav                       15\n",
       "drummer7/session2/96_pop_142_beat_4-4.wav                            9\n",
       "drummer7/session3/11_pop-soft_83_beat_4-4.wav                        8\n",
       "drummer7/session3/24_hiphop_67_beat_4-4.wav                          7\n",
       "drummer8/session1/23_hiphop_70_beat_4-4.wav                          6\n",
       "                                                                    ..\n",
       "drummer5/session1/10_latin-brazilian-sambareggae_96_beat_4-4.wav     1\n",
       "drummer3/session2/23_rock_92_beat_4-4.wav                            1\n",
       "drummer3/session1/21_jazz_120_beat_4-4.wav                           1\n",
       "drummer10/session1/7_jazz-swing_215_beat_4-4.wav                     1\n",
       "drummer1/session2/8_jazz-march_176_beat_4-4.wav                      1\n",
       "Name: count, Length: 91, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.audio_filename.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Generators are the dataloaders for the CNN. They just define how the images are \"fed\" to the cnn, like where is the path to the images, what are the labels to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drummer</th>\n",
       "      <th>session</th>\n",
       "      <th>id</th>\n",
       "      <th>style</th>\n",
       "      <th>simplified_style</th>\n",
       "      <th>bpm</th>\n",
       "      <th>beat_type</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>midi_filename</th>\n",
       "      <th>audio_filename</th>\n",
       "      <th>...</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>spectral_centroid_std</th>\n",
       "      <th>spectral_bandwidth_mean</th>\n",
       "      <th>spectral_bandwidth_std</th>\n",
       "      <th>spectral_flatness_mean</th>\n",
       "      <th>spectral_flatness_std</th>\n",
       "      <th>tempogram_mean</th>\n",
       "      <th>tempogram_std</th>\n",
       "      <th>spectrum_filename</th>\n",
       "      <th>encoded_style</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>drummer5</td>\n",
       "      <td>drummer5/session1</td>\n",
       "      <td>drummer5/session1/2</td>\n",
       "      <td>latin/brazilian/bossa</td>\n",
       "      <td>latin</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>4-4</td>\n",
       "      <td>drummer5/session1/2_latin-brazilian-bossa_127_...</td>\n",
       "      <td>drummer5/session1/2_latin-brazilian-bossa_127_...</td>\n",
       "      <td>...</td>\n",
       "      <td>5696.980657</td>\n",
       "      <td>2379.722855</td>\n",
       "      <td>4577.735043</td>\n",
       "      <td>840.349105</td>\n",
       "      <td>0.082759</td>\n",
       "      <td>0.117818</td>\n",
       "      <td>0.262625</td>\n",
       "      <td>0.168772</td>\n",
       "      <td>drummer5/session1/2_latin-brazilian-bossa_127_...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>drummer8</td>\n",
       "      <td>drummer8/session1</td>\n",
       "      <td>drummer8/session1/19</td>\n",
       "      <td>funk</td>\n",
       "      <td>funk</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>4-4</td>\n",
       "      <td>drummer8/session1/19_funk_108_beat_4-4.mid</td>\n",
       "      <td>drummer8/session1/19_funk_108_beat_4-4.wav</td>\n",
       "      <td>...</td>\n",
       "      <td>6783.231732</td>\n",
       "      <td>3438.914305</td>\n",
       "      <td>5217.666704</td>\n",
       "      <td>1279.332422</td>\n",
       "      <td>0.099487</td>\n",
       "      <td>0.133315</td>\n",
       "      <td>0.171091</td>\n",
       "      <td>0.116500</td>\n",
       "      <td>drummer8/session1/19_funk_108_beat_4-4_52.09-5...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>drummer8</td>\n",
       "      <td>drummer8/session1</td>\n",
       "      <td>drummer8/session1/23</td>\n",
       "      <td>hiphop</td>\n",
       "      <td>hiphop</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>4-4</td>\n",
       "      <td>drummer8/session1/23_hiphop_70_beat_4-4.mid</td>\n",
       "      <td>drummer8/session1/23_hiphop_70_beat_4-4.wav</td>\n",
       "      <td>...</td>\n",
       "      <td>3052.787851</td>\n",
       "      <td>2936.964146</td>\n",
       "      <td>3681.687334</td>\n",
       "      <td>1529.491921</td>\n",
       "      <td>0.019009</td>\n",
       "      <td>0.060377</td>\n",
       "      <td>0.064495</td>\n",
       "      <td>0.084528</td>\n",
       "      <td>drummer8/session1/23_hiphop_70_beat_4-4_135.30...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>drummer1</td>\n",
       "      <td>drummer1/session2</td>\n",
       "      <td>drummer1/session2/10</td>\n",
       "      <td>country</td>\n",
       "      <td>pop</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>4-4</td>\n",
       "      <td>drummer1/session2/10_country_114_beat_4-4.mid</td>\n",
       "      <td>drummer1/session2/10_country_114_beat_4-4.wav</td>\n",
       "      <td>...</td>\n",
       "      <td>4112.338979</td>\n",
       "      <td>2115.908958</td>\n",
       "      <td>4067.074231</td>\n",
       "      <td>993.204167</td>\n",
       "      <td>0.034933</td>\n",
       "      <td>0.072468</td>\n",
       "      <td>0.143729</td>\n",
       "      <td>0.113763</td>\n",
       "      <td>drummer1/session2/10_country_114_beat_4-4_53.7...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>drummer1</td>\n",
       "      <td>drummer1/session2</td>\n",
       "      <td>drummer1/session2/10</td>\n",
       "      <td>country</td>\n",
       "      <td>pop</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>4-4</td>\n",
       "      <td>drummer1/session2/10_country_114_beat_4-4.mid</td>\n",
       "      <td>drummer1/session2/10_country_114_beat_4-4.wav</td>\n",
       "      <td>...</td>\n",
       "      <td>3849.764855</td>\n",
       "      <td>2250.346255</td>\n",
       "      <td>4240.758018</td>\n",
       "      <td>992.058511</td>\n",
       "      <td>0.032331</td>\n",
       "      <td>0.066690</td>\n",
       "      <td>0.180870</td>\n",
       "      <td>0.142363</td>\n",
       "      <td>drummer1/session2/10_country_114_beat_4-4_73.6...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      drummer            session                    id                  style  \\\n",
       "979  drummer5  drummer5/session1   drummer5/session1/2  latin/brazilian/bossa   \n",
       "378  drummer8  drummer8/session1  drummer8/session1/19                   funk   \n",
       "600  drummer8  drummer8/session1  drummer8/session1/23                 hiphop   \n",
       "811  drummer1  drummer1/session2  drummer1/session2/10                country   \n",
       "774  drummer1  drummer1/session2  drummer1/session2/10                country   \n",
       "\n",
       "    simplified_style  bpm  beat_type time_signature  \\\n",
       "979            latin  127          1            4-4   \n",
       "378             funk  108          1            4-4   \n",
       "600           hiphop   70          1            4-4   \n",
       "811              pop  114          1            4-4   \n",
       "774              pop  114          1            4-4   \n",
       "\n",
       "                                         midi_filename  \\\n",
       "979  drummer5/session1/2_latin-brazilian-bossa_127_...   \n",
       "378         drummer8/session1/19_funk_108_beat_4-4.mid   \n",
       "600        drummer8/session1/23_hiphop_70_beat_4-4.mid   \n",
       "811      drummer1/session2/10_country_114_beat_4-4.mid   \n",
       "774      drummer1/session2/10_country_114_beat_4-4.mid   \n",
       "\n",
       "                                        audio_filename  ...  \\\n",
       "979  drummer5/session1/2_latin-brazilian-bossa_127_...  ...   \n",
       "378         drummer8/session1/19_funk_108_beat_4-4.wav  ...   \n",
       "600        drummer8/session1/23_hiphop_70_beat_4-4.wav  ...   \n",
       "811      drummer1/session2/10_country_114_beat_4-4.wav  ...   \n",
       "774      drummer1/session2/10_country_114_beat_4-4.wav  ...   \n",
       "\n",
       "     spectral_centroid_mean spectral_centroid_std  spectral_bandwidth_mean  \\\n",
       "979             5696.980657           2379.722855              4577.735043   \n",
       "378             6783.231732           3438.914305              5217.666704   \n",
       "600             3052.787851           2936.964146              3681.687334   \n",
       "811             4112.338979           2115.908958              4067.074231   \n",
       "774             3849.764855           2250.346255              4240.758018   \n",
       "\n",
       "     spectral_bandwidth_std  spectral_flatness_mean  spectral_flatness_std  \\\n",
       "979              840.349105                0.082759               0.117818   \n",
       "378             1279.332422                0.099487               0.133315   \n",
       "600             1529.491921                0.019009               0.060377   \n",
       "811              993.204167                0.034933               0.072468   \n",
       "774              992.058511                0.032331               0.066690   \n",
       "\n",
       "     tempogram_mean  tempogram_std  \\\n",
       "979        0.262625       0.168772   \n",
       "378        0.171091       0.116500   \n",
       "600        0.064495       0.084528   \n",
       "811        0.143729       0.113763   \n",
       "774        0.180870       0.142363   \n",
       "\n",
       "                                     spectrum_filename  encoded_style  \n",
       "979  drummer5/session1/2_latin-brazilian-bossa_127_...              3  \n",
       "378  drummer8/session1/19_funk_108_beat_4-4_52.09-5...              0  \n",
       "600  drummer8/session1/23_hiphop_70_beat_4-4_135.30...              1  \n",
       "811  drummer1/session2/10_country_114_beat_4-4_53.7...              4  \n",
       "774  drummer1/session2/10_country_114_beat_4-4_73.6...              4  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 828 validated image filenames belonging to 6 classes.\n",
      "Found 186 validated image filenames belonging to 6 classes.\n",
      "Found 186 validated image filenames belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "path_images = os.path.join('..', 'Datasets', SPECTRUM_FOLDERNAME)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Normalize images and add the custom preprocessing function\n",
    "image_generator = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    ")\n",
    "\n",
    "# Define the data generators\n",
    "train_generator = image_generator.flow_from_dataframe(\n",
    "    dataframe=data_train,\n",
    "    directory=path_images,\n",
    "    x_col=\"spectrum_filename\",\n",
    "    y_col=\"simplified_style\",\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    color_mode=\"grayscale\"\n",
    ")\n",
    "\n",
    "val_generator = image_generator.flow_from_dataframe(\n",
    "    dataframe=data_validation,\n",
    "    directory=path_images,\n",
    "    x_col=\"spectrum_filename\",\n",
    "    y_col=\"simplified_style\",\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    color_mode=\"grayscale\", #add color mode,\n",
    "    shuffle=False,  # this is crucial for later evaluation!\n",
    ")\n",
    "\n",
    "test_generator = image_generator.flow_from_dataframe(\n",
    "    dataframe=data_test,\n",
    "    directory=path_images,\n",
    "    x_col=\"spectrum_filename\",\n",
    "    y_col=\"simplified_style\",\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    color_mode=\"grayscale\", #add color mode,\n",
    "    shuffle=False,  # this is crucial for later evaluation!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 200, 500, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 200, 500, 204)     114444    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 200, 500, 204)    816       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 200, 1, 204)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 200, 1, 204)       40783884  \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 200, 1, 204)      816       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 200, 1, 204)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 200, 1, 51)        1331763   \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 200, 1, 51)       204       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 200, 1, 51)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 200, 1, 51)        166515    \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 200, 1, 51)       204       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 200, 1, 51)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 200, 1, 51)        83283     \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 200, 1, 51)       204       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 200, 1, 51)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 10200)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                652864    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43,135,387\n",
      "Trainable params: 43,134,265\n",
      "Non-trainable params: 1,122\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, BatchNormalization, MaxPooling2D, Flatten, Dense\n",
    "from keras.models import Model\n",
    "from tensorflow import squeeze, pad\n",
    "\n",
    "# Define the input shape\n",
    "inputs = Input(shape=(IMG_HEIGHT, IMG_WIDTH, 1))\n",
    "\n",
    "num_filt = 1.6\n",
    "yInput = IMG_HEIGHT     # yInput is the number of mel bins in practice.\n",
    "\n",
    "# timbral block 1\n",
    "conv1 = Conv2D(int(num_filt*128), [7, int(0.4 * yInput)], padding=\"same\", activation='relu')(inputs)\n",
    "bn_conv1 = BatchNormalization(axis=-1)(conv1)\n",
    "pool1 = MaxPooling2D(pool_size=[1, bn_conv1.shape[2]], strides=[1, bn_conv1.shape[2]])(bn_conv1)\n",
    "\n",
    "# timbral block 2\n",
    "conv2 = Conv2D(int(num_filt*128), [7, int(0.7 * yInput)], padding=\"same\", activation='relu')(pool1)\n",
    "bn_conv2 = BatchNormalization(axis=-1)(conv2)\n",
    "pool2 = MaxPooling2D(pool_size=[1, bn_conv2.shape[2]], strides=[1, bn_conv2.shape[2]])(bn_conv2)\n",
    "\n",
    "# temporal block 1\n",
    "conv3 = Conv2D(int(num_filt*32), (128, 1), padding=\"same\", activation='relu')(pool2)\n",
    "bn_conv3 = BatchNormalization(axis=-1)(conv3)\n",
    "pool3 = MaxPooling2D(pool_size=[1, bn_conv3.shape[2]], strides=[1, bn_conv3.shape[2]])(bn_conv3)\n",
    "\n",
    "# temporal block 2\n",
    "conv4 = Conv2D(int(num_filt*32), (64, 1), padding=\"same\", activation='relu')(pool3)\n",
    "bn_conv4 = BatchNormalization(axis=-1)(conv4)\n",
    "pool4 = MaxPooling2D(pool_size=[1, bn_conv4.shape[2]], strides=[1, bn_conv4.shape[2]])(bn_conv4)\n",
    "\n",
    "# temporal block 3\n",
    "conv5 = Conv2D(int(num_filt*32), (32, 1), padding=\"same\", activation='relu')(pool4)\n",
    "bn_conv5 = BatchNormalization(axis=-1)(conv5)\n",
    "pool5 = MaxPooling2D(pool_size=[1, bn_conv5.shape[2]], strides=[1, bn_conv5.shape[2]])(bn_conv5)\n",
    "\n",
    "# dense layer\n",
    "x = Flatten()(pool5)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "outputs = Dense(6, activation=\"softmax\")(x)\n",
    "\n",
    "# Create the model\n",
    "cnn_model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# Define the input shape\n",
    "inputs = Input(shape=(IMG_HEIGHT, IMG_WIDTH, 1))\n",
    "\n",
    "# Define the CNN architecture\n",
    "x = Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "outputs = Dense(6, activation=\"softmax\")(x)\n",
    "\n",
    "# Create the model\n",
    "cnn_model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def compileCNN(cnn):\n",
    "    metrics = [\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    "\n",
    "    # Compile the model\n",
    "    cnn.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy', # used for one-hot encoded labels, which is done by the ImageDataGenerator\n",
    "                metrics=\"accuracy\") #metrics)\n",
    "    \n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCallbacks(path):\n",
    "    # Create a callback that saves the model's weights\n",
    "    checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(filepath=path,\n",
    "                                                    save_weights_only=True,    # saving only the weights, because we have the architecture of the model\n",
    "                                                    verbose=1, \n",
    "                                                    monitor='val_accuracy',    # we are monitoring the accuracy on the validation set\n",
    "                                                    mode='max',                # the greatest accuracy on the validation is the best outcome\n",
    "                                                    save_best_only=True)       # we only want to save the best model. The other chechpoints are not interesting to us\n",
    "    \n",
    "    early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=EARLY_STOPPING_PATIENCE)\n",
    "\n",
    "    return checkpoint_cb, early_stopping_cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainCNN(cnn, train_generator, validation_generator, checkpoint_callback, early_stopping_callback):\n",
    "    history = cnn.fit(\n",
    "        train_generator,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=validation_generator,\n",
    "        verbose=1,\n",
    "        callbacks=[checkpoint_callback, early_stopping_callback],  # Pass callback to training\n",
    "    )\n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 2.4109 - accuracy: 0.2005 \n",
      "Epoch 1: val_accuracy improved from -inf to 0.17742, saving model to ..\\data\\models\\multiclass_cnn_UPDATED_ARCHITECTURE.ckpt\n",
      "26/26 [==============================] - 1479s 31s/step - loss: 2.4109 - accuracy: 0.2005 - val_loss: 49.2188 - val_accuracy: 0.1774\n",
      "Epoch 2/100\n",
      "12/26 [============>.................] - ETA: 3:05 - loss: 1.8450 - accuracy: 0.2135WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-5.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-5.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-5.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-5.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-6.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-6.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-5.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-5.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-6.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-6.bias\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 5\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 5\u001b[0m     \u001b[43mcnn_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcnn_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Programmierung\\anaconda3\\envs\\audio_data_science_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Programmierung\\anaconda3\\envs\\audio_data_science_gpu\\lib\\site-packages\\tensorflow\\python\\training\\py_checkpoint_reader.py:31\u001b[0m, in \u001b[0;36merror_translator\u001b[1;34m(e)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot found in checkpoint\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_message \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFailed to find any \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatching files for\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m error_message:\n\u001b[1;32m---> 31\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors_impl\u001b[38;5;241m.\u001b[39mNotFoundError(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, error_message)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSliced checkpoints are not supported\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_message \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData type \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupported\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m error_message:\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ..\\data\\models\\multiclass_cnn_UPDATED_ARCHITECTURE.ckpt",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m cnn_model \u001b[38;5;241m=\u001b[39m compileCNN(cnn_model)\n\u001b[0;32m      8\u001b[0m checkpoint_callback, early_stopping_callback \u001b[38;5;241m=\u001b[39m createCallbacks(cnn_path)\n\u001b[1;32m----> 9\u001b[0m cnn_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrainCNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcnn_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_callback\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[33], line 2\u001b[0m, in \u001b[0;36mtrainCNN\u001b[1;34m(cnn, train_generator, validation_generator, checkpoint_callback, early_stopping_callback)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrainCNN\u001b[39m(cnn, train_generator, validation_generator, checkpoint_callback, early_stopping_callback):\n\u001b[1;32m----> 2\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mcnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Pass callback to training\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cnn\n",
      "File \u001b[1;32md:\\Programmierung\\anaconda3\\envs\\audio_data_science_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\Programmierung\\anaconda3\\envs\\audio_data_science_gpu\\lib\\site-packages\\keras\\engine\\training.py:1570\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1568\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs\n\u001b[0;32m   1569\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[1;32m-> 1570\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[0;32m   1572\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32md:\\Programmierung\\anaconda3\\envs\\audio_data_science_gpu\\lib\\site-packages\\keras\\callbacks.py:470\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 470\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Programmierung\\anaconda3\\envs\\audio_data_science_gpu\\lib\\site-packages\\keras\\callbacks.py:317\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 317\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n",
      "File \u001b[1;32md:\\Programmierung\\anaconda3\\envs\\audio_data_science_gpu\\lib\\site-packages\\keras\\callbacks.py:340\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    337\u001b[0m     batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 340\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    343\u001b[0m     end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[1;32md:\\Programmierung\\anaconda3\\envs\\audio_data_science_gpu\\lib\\site-packages\\keras\\callbacks.py:388\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m    387\u001b[0m     hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 388\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32md:\\Programmierung\\anaconda3\\envs\\audio_data_science_gpu\\lib\\site-packages\\keras\\callbacks.py:1081\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m-> 1081\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Programmierung\\anaconda3\\envs\\audio_data_science_gpu\\lib\\site-packages\\keras\\callbacks.py:1157\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1156\u001b[0m     \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32md:\\Programmierung\\anaconda3\\envs\\audio_data_science_gpu\\lib\\site-packages\\keras\\utils\\tf_utils.py:635\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m--> 635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Programmierung\\anaconda3\\envs\\audio_data_science_gpu\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32md:\\Programmierung\\anaconda3\\envs\\audio_data_science_gpu\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32md:\\Programmierung\\anaconda3\\envs\\audio_data_science_gpu\\lib\\site-packages\\keras\\utils\\tf_utils.py:628\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m--> 628\u001b[0m         t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;66;03m# as-is.\u001b[39;00m\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n",
      "File \u001b[1;32md:\\Programmierung\\anaconda3\\envs\\audio_data_science_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1157\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \n\u001b[0;32m   1136\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32md:\\Programmierung\\anaconda3\\envs\\audio_data_science_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1123\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1122\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1124\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "filename = 'multiclass_cnn_' + FILE_SUFFIX + '.ckpt'\n",
    "cnn_path = os.path.join('..', 'data', 'models', filename)\n",
    "\n",
    "try:\n",
    "    cnn_model.load_weights(cnn_path)\n",
    "except:\n",
    "    cnn_model = compileCNN(cnn_model)\n",
    "    checkpoint_callback, early_stopping_callback = createCallbacks(cnn_path)\n",
    "    cnn_model = trainCNN(cnn_model, train_generator, val_generator, checkpoint_callback, early_stopping_callback)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "tf.debugging.disable_traceback_filtering()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 4s 793ms/step - loss: 6.9215 - accuracy: 0.2151\n",
      "Test Accuracy: 21.51%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = cnn_model.evaluate(test_generator)\n",
    "print(f'Test Accuracy: {test_accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 69ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Predict the labels for the test set\n",
    "test_generator.reset()  # Resetting ensures the generator starts from the beginning\n",
    "predictions = cnn_model.predict(test_generator)\n",
    "\n",
    "# Convert predictions to class indices (if using softmax output)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# True labels from the test generator\n",
    "true_classes = test_generator.classes\n",
    "class_labels = list(test_generator.class_indices.keys())  # Get the class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, hamming_loss, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def evaluate_model(true_classes, predicted_classes):\n",
    "    # Classification report\n",
    "    report = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "\n",
    "    # Hamming Loss\n",
    "    h_loss = hamming_loss(true_classes, predicted_classes)\n",
    "    print(\"Hamming Loss:\", h_loss)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_labels, yticklabels=class_labels)\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "    \n",
    "    return report, h_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the classification report to a markdown table\n",
    "def convert_to_markdown(report, hamming_loss, image_path=None, file_suffix=FILE_SUFFIX):\n",
    "    lines = report.strip().split('\\n')\n",
    "    headers = lines[0].split()\n",
    "    table = \"| \" + \" | \".join(headers) + \" |\\n\"\n",
    "    table += \"| \" + \" | \".join(['---'] * len(headers)) + \" |\\n\"\n",
    "    \n",
    "    for line in lines[1:]:\n",
    "        row = \" | \".join(line.split())\n",
    "        table += \"| \" + row + \" |\\n\"\n",
    "    \n",
    "    markdown_content = f\"# Classification Report for {file_suffix}\\n\\n\"\n",
    "    markdown_content += f\"__Hamming Loss__ = {hamming_loss}\\n\\n{table}\\n\"\n",
    "    \n",
    "    if image_path:\n",
    "        markdown_content += f\"\\n![Image]({image_path})\\n\"\n",
    "    \n",
    "    return markdown_content\n",
    "\n",
    "def save_evaluation(report, h_loss, file_suffix=FILE_SUFFIX):\n",
    "    eval_path = os.path.join('..', 'evaluation')\n",
    "    conf_matrix_path = os.path.join(eval_path, 'images', 'confusion_matrix_' + file_suffix + '.png')\n",
    "    markdwon_path = os.path.join(eval_path, 'markdown', 'classification_report_' + file_suffix + '.md')\n",
    "    plt.savefig(conf_matrix_path)\n",
    "    #plt.close()\n",
    "\n",
    "    # Generate markdown content\n",
    "    markdown_content = convert_to_markdown(report, h_loss, conf_matrix_path, file_suffix=file_suffix)\n",
    "\n",
    "    # Write to a markdown file\n",
    "    with open(markdwon_path, \"w\") as file:\n",
    "        file.write(markdown_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        funk       0.11      0.14      0.12        28\n",
      "      hiphop       0.33      0.19      0.25        36\n",
      "        jazz       0.18      0.21      0.19        29\n",
      "       latin       0.38      0.48      0.43        27\n",
      "         pop       0.24      0.11      0.15        36\n",
      "        rock       0.14      0.20      0.16        30\n",
      "\n",
      "    accuracy                           0.22       186\n",
      "   macro avg       0.23      0.22      0.22       186\n",
      "weighted avg       0.23      0.22      0.21       186\n",
      "\n",
      "Hamming Loss: 0.7849462365591398\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "report, h_loss = evaluate_model(true_classes, predicted_classes)\n",
    "save_evaluation(report, h_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_baseline = []\n",
    "all_5s_baseline = []\n",
    "\n",
    "for i in range(len(true_classes)):\n",
    "    random_baseline.append(np.random.randint(0, 6))\n",
    "    all_5s_baseline.append(5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "rnd_report, rnd_h_loss = evaluate_model(true_classes, random_baseline)\n",
    "save_evaluation(rnd_report, rnd_h_loss, file_suffix='RANDOM_BASELINE')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "all_5s_report, all_5s_h_loss = evaluate_model(true_classes, all_5s_baseline)\n",
    "save_evaluation(all_5s_report, all_5s_h_loss, file_suffix='ALL_5S_BASELINE')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
